/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * KNOUX Player Xâ„¢ - OpenRouter AI Service
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * 
 * Ø®Ø¯Ù…Ø© OpenRouter AI - ÙˆØ§Ø¬Ù‡Ø© Ù…Ø¬Ø§Ù†ÙŠØ© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ù‚ÙˆÙŠØ©
 * ØªØ¯Ø¹Ù…: Llama, Mistral, Qwen, DeepSeek, ÙˆØ£ÙƒØ«Ø±
 * 
 * @module Services/AI
 * @author KNOUX Development Team
 * @version 2.0.0
 */

import EventEmitter from 'events';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
}

export interface ChatContext {
  messages: ChatMessage[];
  currentMedia?: string;
  mediaInfo?: {
    title: string;
    artist?: string;
    duration: number;
  };
}

export interface MediaAnalysis {
  summary: string;
  tags: string[];
  mood: string;
  recommendations: string[];
}

export interface PlaylistRecommendation {
  title: string;
  reason: string;
  confidence: number;
}

export interface AIModel {
  id: string;
  name: string;
  description: string;
  contextLength: number;
  pricing: {
    prompt: number;
    completion: number;
  };
}

export interface ServiceStatus {
  isOnline: boolean;
  latency: number;
  model: string;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ù†Ù…Ø§Ø°Ø¬ AI Ø§Ù„Ù…ØªØ§Ø­Ø© (Ù…Ø¬Ø§Ù†ÙŠØ©)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const AVAILABLE_MODELS: AIModel[] = [
  {
    id: 'meta-llama/llama-3.2-11b-vision-instruct:free',
    name: 'Llama 3.2 11B Vision',
    description: 'Ù†Ù…ÙˆØ°Ø¬ Meta Ø§Ù„Ù‚ÙˆÙŠ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø±Ø¤ÙŠØ©',
    contextLength: 131072,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'google/gemma-2-9b-it:free',
    name: 'Gemma 2 9B',
    description: 'Ù†Ù…ÙˆØ°Ø¬ Google Ø§Ù„Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±',
    contextLength: 8192,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'microsoft/phi-3.5-mini-instruct:free',
    name: 'Phi 3.5 Mini',
    description: 'Ù†Ù…ÙˆØ°Ø¬ Microsoft Ø§Ù„Ù…Ø¯Ù…Ø¬ ÙˆØ§Ù„Ø³Ø±ÙŠØ¹',
    contextLength: 131072,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'nvidia/llama-3.1-nemotron-70b-instruct:free',
    name: 'Nemotron 70B',
    description: 'Ù†Ù…ÙˆØ°Ø¬ NVIDIA Ø§Ù„Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹',
    contextLength: 131072,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'deepseek/deepseek-chat:free',
    name: 'DeepSeek Chat',
    description: 'Ù†Ù…ÙˆØ°Ø¬ DeepSeek Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª',
    contextLength: 65536,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'qwen/qwen-2-7b-instruct:free',
    name: 'Qwen 2 7B',
    description: 'Ù†Ù…ÙˆØ°Ø¬ Alibaba Ø§Ù„Ù‚ÙˆÙŠ',
    contextLength: 32768,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'huggingfaceh4/zephyr-7b-beta:free',
    name: 'Zephyr 7B',
    description: 'Ù†Ù…ÙˆØ°Ø¬ Hugging Face Ø§Ù„Ù…Ø­Ø³Ù‘Ù†',
    contextLength: 32768,
    pricing: { prompt: 0, completion: 0 },
  },
  {
    id: 'gryphe/mythomist-7b:free',
    name: 'MythoMist 7B',
    description: 'Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆØ§Ø²Ù† Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª',
    contextLength: 32768,
    pricing: { prompt: 0, completion: 0 },
  },
];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ÙØ¦Ø© Ø®Ø¯Ù…Ø© OpenRouter
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class OpenRouterService extends EventEmitter {
  private apiKey: string | null = null;
  private baseUrl = 'https://openrouter.ai/api/v1';
  private currentModel: string = AVAILABLE_MODELS[0].id;
  private context: ChatContext = { messages: [] };
  private isInitialized = false;
  private abortController: AbortController | null = null;
  private requestQueue: Promise<any> = Promise.resolve();
  private status: ServiceStatus = {
    isOnline: false,
    latency: 0,
    model: AVAILABLE_MODELS[0].id,
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Ø§Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆØ§Ù„Ø¥ØºÙ„Ø§Ù‚
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async initialize(): Promise<void> {
    if (this.isInitialized) return;

    try {
      console.log('ğŸš€ Initializing OpenRouter AI Service...');

      // Get API key from settings
      this.apiKey = await window.knouxAPI.settings.get<string>('openRouterApiKey', '');

      if (this.apiKey) {
        // Load saved model preference
        const savedModel = await window.knouxAPI.settings.get<string>('aiModel', '');
        if (savedModel && AVAILABLE_MODELS.some(m => m.id === savedModel)) {
          this.currentModel = savedModel;
        }

        // Test connection
        await this.testConnection();
      }

      this.isInitialized = true;
      console.log('âœ… OpenRouter Service initialized with model:', this.currentModel);
      this.emit('initialized', { model: this.currentModel });
    } catch (error) {
      console.error('âŒ Failed to initialize OpenRouter Service:', error);
      this.emit('error', error);
      throw error;
    }
  }

  public async shutdown(): Promise<void> {
    if (this.abortController) {
      this.abortController.abort();
    }
    this.isInitialized = false;
    this.context = { messages: [] };
    console.log('ğŸ›‘ OpenRouter Service shutdown');
    this.emit('shutdown');
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private async testConnection(): Promise<boolean> {
    if (!this.apiKey) return false;

    const startTime = Date.now();
    
    try {
      const response = await fetch(`${this.baseUrl}/models`, {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'HTTP-Referer': 'https://knoux-player.app',
          'X-Title': 'KNOUX Player X',
        },
      });

      this.status.latency = Date.now() - startTime;
      this.status.isOnline = response.ok;
      this.status.model = this.currentModel;

      if (response.ok) {
        console.log(`ğŸŒ OpenRouter connected (${this.status.latency}ms)`);
        this.emit('connected', this.status);
      }

      return response.ok;
    } catch (error) {
      this.status.isOnline = false;
      console.error('âŒ Connection test failed:', error);
      this.emit('connection-failed', error);
      return false;
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Ø§Ù„Ø·Ù„Ø¨Ø§Øª API
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private async makeRequest(endpoint: string, body: any): Promise<any> {
    if (!this.apiKey) {
      throw new Error('API key not configured');
    }

    return this.requestQueue = this.requestQueue.then(async () => {
      this.abortController = new AbortController();

      try {
        const response = await fetch(`${this.baseUrl}${endpoint}`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': 'https://knoux-player.app',
            'X-Title': 'KNOUX Player X',
          },
          body: JSON.stringify(body),
          signal: this.abortController.signal,
        });

        if (!response.ok) {
          const error = await response.json().catch(() => ({ error: { message: 'Unknown error' } }));
          throw new Error(error.error?.message || `HTTP ${response.status}`);
        }

        return response.json();
      } catch (error) {
        if (error instanceof Error && error.name === 'AbortError') {
          throw new Error('Request cancelled');
        }
        throw error;
      }
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async chat(message: string, context?: ChatContext): Promise<string> {
    if (!this.apiKey) {
      return 'âš ï¸ OpenRouter AI is not configured. Please set your API key in settings to use free AI models like Llama, Mistral, and more.';
    }

    try {
      // Update context if provided
      if (context) {
        this.context = { ...this.context, ...context };
      }

      // Build messages array
      const messages = this.buildMessages(message);

      // Send request
      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages,
        temperature: 0.7,
        max_tokens: 2048,
        top_p: 0.9,
      });

      const content = response.choices?.[0]?.message?.content || 'No response';

      // Store in context
      this.context.messages.push(
        { role: 'user', content: message, timestamp: new Date() },
        { role: 'assistant', content, timestamp: new Date() }
      );

      // Keep only last 20 messages
      if (this.context.messages.length > 20) {
        this.context.messages = this.context.messages.slice(-20);
      }

      this.emit('message', { role: 'assistant', content });
      return content;
    } catch (error) {
      console.error('Chat error:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      return `âŒ Error: ${errorMessage}. Please try again or check your API key.`;
    }
  }

  public async *streamChat(message: string): AsyncGenerator<string> {
    if (!this.apiKey) {
      yield 'âš ï¸ Please configure your OpenRouter API key in settings to access free AI models.';
      return;
    }

    try {
      const messages = this.buildMessages(message);

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': 'https://knoux-player.app',
          'X-Title': 'KNOUX Player X',
        },
        body: JSON.stringify({
          model: this.currentModel,
          messages,
          temperature: 0.7,
          max_tokens: 2048,
          stream: true,
        }),
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const reader = response.body?.getReader();
      if (!reader) throw new Error('No response body');

      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') return;

            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                yield content;
              }
            } catch {
              // Ignore parse errors
            }
          }
        }
      }
    } catch (error) {
      console.error('Stream chat error:', error);
      yield `âŒ Error: ${error instanceof Error ? error.message : 'Unknown error'}`;
    }
  }

  private buildMessages(userMessage: string): any[] {
    const messages: any[] = [
      {
        role: 'system',
        content: `You are KNOUX AI, an intelligent assistant for KNOUX Player X media player. 
You help users with media playback, playlist creation, library management, and answer questions about their media.
Be concise, helpful, and friendly. Use emojis occasionally to make responses engaging.
Current date: ${new Date().toLocaleDateString()}
${this.context.currentMedia ? `Currently playing: "${this.context.mediaInfo?.title}" by ${this.context.mediaInfo?.artist || 'Unknown'}` : ''}`,
      },
    ];

    // Add recent context
    this.context.messages.slice(-10).forEach(msg => {
      messages.push({
        role: msg.role,
        content: msg.content,
      });
    });

    // Add current message with context
    let enhancedMessage = userMessage;
    if (this.context.currentMedia && this.context.mediaInfo) {
      enhancedMessage = `[Context: Playing "${this.context.mediaInfo.title}" by ${this.context.mediaInfo.artist || 'Unknown'}] ${userMessage}`;
    }

    messages.push({ role: 'user', content: enhancedMessage });

    return messages;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async analyzeMedia(filePath: string): Promise<MediaAnalysis> {
    if (!this.apiKey) {
      return {
        summary: 'AI analysis requires OpenRouter API key. Get a free key at openrouter.ai',
        tags: [],
        mood: 'unknown',
        recommendations: [],
      };
    }

    try {
      const fileName = filePath.split('/').pop() || filePath;
      
      const prompt = `Analyze this media file: "${fileName}". 
Provide a brief analysis in JSON format with these fields:
- summary: 1-2 sentence description
- tags: array of 3-5 relevant tags
- mood: overall mood/atmosphere
- recommendations: array of 3 similar content suggestions

Respond ONLY with valid JSON.`;

      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.5,
        max_tokens: 500,
      });

      const content = response.choices?.[0]?.message?.content || '{}';

      // Try to parse JSON response
      try {
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          const analysis = JSON.parse(jsonMatch[0]);
          return {
            summary: analysis.summary || 'No summary available',
            tags: Array.isArray(analysis.tags) ? analysis.tags : [],
            mood: analysis.mood || 'unknown',
            recommendations: Array.isArray(analysis.recommendations) ? analysis.recommendations : [],
          };
        }
      } catch {
        // Fallback
      }

      return {
        summary: content.substring(0, 200),
        tags: [],
        mood: 'unknown',
        recommendations: [],
      };
    } catch (error) {
      console.error('Media analysis error:', error);
      return {
        summary: 'Analysis failed. Please try again.',
        tags: [],
        mood: 'unknown',
        recommendations: [],
      };
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ØªÙˆØµÙŠØ§Øª Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async generatePlaylist(mood: string, count = 10): Promise<string[]> {
    if (!this.apiKey) {
      return [];
    }

    try {
      const prompt = `Generate a playlist of ${count} songs/movies for a "${mood}" mood. 
Return ONLY the titles, one per line, no numbering or extra text.`;

      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.8,
        max_tokens: 500,
      });

      const text = response.choices?.[0]?.message?.content || '';

      return text
        .split('\n')
        .map(line => line.trim())
        .filter(line => line.length > 0 && !line.match(/^\d+\./) && !line.startsWith('-'));
    } catch (error) {
      console.error('Playlist generation error:', error);
      return [];
    }
  }

  public async getRecommendations(basedOn: string[]): Promise<PlaylistRecommendation[]> {
    if (!this.apiKey || basedOn.length === 0) {
      return [];
    }

    try {
      const prompt = `Based on these items: ${basedOn.join(', ')}, 
recommend 5 similar movies/songs. 
Format each as: Title - Brief reason why it's similar
One per line.`;

      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 500,
      });

      const text = response.choices?.[0]?.message?.content || '';

      return text
        .split('\n')
        .filter(line => line.trim().length > 0)
        .map(line => {
          const parts = line.split(' - ');
          return {
            title: parts[0]?.replace(/^\d+\.\s*/, '').trim() || line,
            reason: parts[1]?.trim() || '',
            confidence: 0.8,
          };
        });
    } catch (error) {
      console.error('Recommendations error:', error);
      return [];
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async getHelp(topic: string): Promise<string> {
    const helpTopics: Record<string, string> = {
      playback: `ğŸ¬ Playback Controls:
â€¢ Space: Play/Pause
â€¢ â†/â†’ Arrow: Seek backward/forward 10s
â€¢ â†‘/â†“ Arrow: Volume up/down
â€¢ F: Fullscreen toggle
â€¢ M: Mute toggle
â€¢ S: Take screenshot`,

      playlist: `ğŸ“‹ Playlist Management:
â€¢ Drag & drop files to add
â€¢ Double-click to play
â€¢ Right-click for options
â€¢ Ctrl+Shift+O: Open folder
â€¢ Use AI to generate playlists based on mood`,

      subtitles: `ğŸ“ Subtitle Controls:
â€¢ V: Toggle subtitles
â€¢ Shift+L: Load subtitle file
â€¢ +/-: Adjust subtitle delay
â€¢ AI Sync: Auto-sync subtitles`,

      audio: `ğŸµ Audio Controls:
â€¢ Use equalizer in Audio menu
â€¢ Enable Neural DSP for enhanced sound
â€¢ Select audio tracks from menu
â€¢ Adjust spatial audio settings`,

      ai: `ğŸ¤– AI Features:
â€¢ Chat with KNOUX AI for help
â€¢ Auto-generate playlists by mood
â€¢ Get media recommendations
â€¢ Smart subtitle synchronization
â€¢ Media content analysis`,

      shortcuts: `âŒ¨ï¸ Keyboard Shortcuts:
â€¢ Ctrl+O: Open file
â€¢ Ctrl+Shift+O: Open folder
â€¢ Ctrl+L: Show library
â€¢ F11: Fullscreen
â€¢ Esc: Exit fullscreen`,
    };

    return helpTopics[topic.toLowerCase()] || 
      `ğŸ’¡ I can help you with: playback, playlist, subtitles, audio, ai, shortcuts. Just ask!`;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async setApiKey(apiKey: string): Promise<void> {
    this.apiKey = apiKey;
    await window.knouxAPI.settings.set('openRouterApiKey', apiKey);
    
    if (apiKey) {
      await this.testConnection();
    }
    
    this.emit('api-key-set');
  }

  public async setModel(modelId: string): Promise<void> {
    if (!AVAILABLE_MODELS.some(m => m.id === modelId)) {
      throw new Error('Invalid model ID');
    }

    this.currentModel = modelId;
    this.status.model = modelId;
    await window.knouxAPI.settings.set('aiModel', modelId);
    this.emit('model-changed', modelId);
  }

  public getAvailableModels(): AIModel[] {
    return AVAILABLE_MODELS;
  }

  public getCurrentModel(): string {
    return this.currentModel;
  }

  public getStatus(): ServiceStatus {
    return { ...this.status };
  }

  public hasApiKey(): boolean {
    return !!this.apiKey;
  }

  public clearContext(): void {
    this.context = { messages: [] };
    this.emit('context-cleared');
  }

  public setCurrentMedia(mediaInfo: ChatContext['mediaInfo']): void {
    this.context.currentMedia = mediaInfo?.title;
    this.context.mediaInfo = mediaInfo;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ÙˆØ¸Ø§Ø¦Ù Ø¥Ø¶Ø§ÙÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async summarizeContent(text: string, maxLength = 100): Promise<string> {
    if (!this.apiKey) return text.substring(0, maxLength);

    try {
      const prompt = `Summarize this in ${maxLength} characters or less:\n${text}`;
      
      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.3,
        max_tokens: 100,
      });

      return response.choices?.[0]?.message?.content || text.substring(0, maxLength);
    } catch {
      return text.substring(0, maxLength);
    }
  }

  public async translateText(text: string, targetLang: string): Promise<string> {
    if (!this.apiKey) return text;

    try {
      const prompt = `Translate to ${targetLang}:\n${text}`;
      
      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.3,
        max_tokens: 500,
      });

      return response.choices?.[0]?.message?.content || text;
    } catch {
      return text;
    }
  }

  public async generateSubtitles(audioContext: string): Promise<string[]> {
    if (!this.apiKey) return [];

    try {
      const prompt = `Generate subtitle timestamps for this audio context:\n${audioContext}\nFormat: [HH:MM:SS] Text`;
      
      const response = await this.makeRequest('/chat/completions', {
        model: this.currentModel,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.5,
        max_tokens: 1000,
      });

      const text = response.choices?.[0]?.message?.content || '';
      return text.split('\n').filter(line => line.trim().length > 0);
    } catch {
      return [];
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Singleton Instance
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const openRouterService = new OpenRouterService();
export default openRouterService;
